{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. import needed package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-13T12:35:49.792616Z",
     "start_time": "2018-03-13T12:35:49.782331Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from mxnet import autograd\n",
    "from mxnet import gluon\n",
    "from mxnet import image\n",
    "from mxnet import init\n",
    "from mxnet import nd\n",
    "from mxnet.gluon.model_zoo import vision as model\n",
    "from mxnet.gluon import nn\n",
    "from mxnet.gluon.data import vision\n",
    "import numpy as np\n",
    "import random\n",
    "import mxnet as mx\n",
    "import sys\n",
    "sys.path.insert(0, '../../utils')\n",
    "from dataset import *\n",
    "from netlib import *\n",
    "import os\n",
    "import shutil\n",
    "import utils\n",
    "\n",
    "ctx = mx.gpu(0)\n",
    "\n",
    "def mkdir_if_not_exist(path):\n",
    "    if not os.path.exists(os.path.join(*path)):\n",
    "        os.makedirs(os.path.join(*path))\n",
    "        \n",
    "arrayds_dir = '/home/hui/dataset/CIFAR10/arraydataset/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. data loader, data argument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-13T12:35:50.948980Z",
     "start_time": "2018-03-13T12:35:50.920113Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "data loader\n",
    "\"\"\"\n",
    "def _transform_test(data, label):\n",
    "    im = data.astype('float32') / 255\n",
    "    auglist = image.CreateAugmenter(data_shape=(3, 32, 32), mean=np.array([0.4914, 0.4822, 0.4465]),\n",
    "                                   std=np.array([0.2023, 0.1994, 0.2010]))\n",
    "    for aug in auglist:\n",
    "        im = aug(im)\n",
    "    im = nd.transpose(im, (2, 0, 1))\n",
    "    return im, nd.array([label]).astype('float32')\n",
    "\n",
    "def load_all_data_label(pathes):\n",
    "    all_data, all_label = None, None\n",
    "    for path in pathes:\n",
    "        data, label = nd.load(path)\n",
    "        label = label.reshape((-1,)).astype('float32')\n",
    "        if all_data is None:\n",
    "            all_data, all_label = data, label\n",
    "        else:\n",
    "            all_data = nd.concat(all_data, data, dim=0)\n",
    "            all_label = nd.concat(all_label, label, dim=0)\n",
    "    return all_data, all_label\n",
    "\n",
    "\n",
    "def data_loader(batch_size, transform_train, transform_test=None, num_workers=0, pathes=None, arrayds=False):\n",
    "    if transform_train is None:\n",
    "        transform_train = _transform_train\n",
    "    if transform_test is None:\n",
    "        transform_test = _transform_test\n",
    "        \n",
    "    # flag=1 mean 3 channel image\n",
    "    if pathes is None:\n",
    "        train_ds = gluon.data.vision.datasets.CIFAR100(train=True, transform=transform_train)\n",
    "    else:\n",
    "        if not arrayds:\n",
    "            train_ds = MultiFolderDataset(pathes, transform=transform_train)\n",
    "        else:\n",
    "            train_ds = MyArrayDataset(load_all_data_label(pathes), transform=transform_train)\n",
    "    test_ds = gluon.data.vision.datasets.CIFAR100(train=False, transform=transform_test)\n",
    "\n",
    "    loader = gluon.data.DataLoader\n",
    "    train_data = loader(train_ds, batch_size, shuffle=True, last_batch='keep', num_workers=num_workers)\n",
    "    test_data = loader(test_ds, batch_size, shuffle=False, last_batch='keep', num_workers=num_workers)\n",
    "    return train_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-13T12:35:51.748814Z",
     "start_time": "2018-03-13T12:35:51.708471Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "data argument\n",
    "\"\"\"\n",
    "def transform_train_DA1(data, label):\n",
    "    im = data.asnumpy()\n",
    "    im = np.pad(im, ((4, 4), (4, 4), (0, 0)), mode='constant', constant_values=0)\n",
    "    im = nd.array(im, dtype='float32') / 255\n",
    "    auglist = image.CreateAugmenter(data_shape=(3, 32, 32), resize=0, rand_mirror=True,\n",
    "                                    rand_crop=True,\n",
    "                                   mean=np.array([0.4914, 0.4822, 0.4465]),\n",
    "                                   std=np.array([0.2023, 0.1994, 0.2010]))\n",
    "    for aug in auglist:\n",
    "        im = aug(im)\n",
    "    im = nd.transpose(im, (2, 0, 1)) # channel x width x height\n",
    "    return im, nd.array([label]).astype('float32')\n",
    "\n",
    "\n",
    "def transform_train_DA2(data, label):\n",
    "    im = data.astype(np.float32) / 255\n",
    "    auglist = [image.RandomSizedCropAug(size=(32, 32), min_area=0.49, ratio=(0.5, 2))]\n",
    "    _aug = image.CreateAugmenter(data_shape=(3, 32, 32), resize=0, \n",
    "                                rand_crop=False, rand_resize=False, rand_mirror=True,\n",
    "                                mean=np.array([0.4914, 0.4822, 0.4465]),\n",
    "                                std=np.array([0.2023, 0.1994, 0.2010]),\n",
    "                                brightness=0.3, contrast=0.3, saturation=0.3, hue=0.3,\n",
    "                                pca_noise=0.01, rand_gray=0, inter_method=2)\n",
    "    auglist.append(image.RandomOrderAug(_aug))\n",
    "    \n",
    "    for aug in auglist:\n",
    "        im = aug(im)\n",
    "    \n",
    "    im = nd.transpose(im, (2, 0, 1))\n",
    "    return (im, nd.array([label]).asscalar().astype('float32'))\n",
    "    \n",
    "\n",
    "random_clip_rate = 0.3\n",
    "def transform_train_DA3(data, label):\n",
    "    im = data.astype(np.float32) / 255\n",
    "    auglist = [image.RandomSizedCropAug(size=(32, 32), min_area=0.49, ratio=(0.5, 2))]\n",
    "    _aug = image.CreateAugmenter(data_shape=(3, 32, 32), resize=0, \n",
    "                                rand_crop=False, rand_resize=False, rand_mirror=True,\n",
    "#                                mean=np.array([0.4914, 0.4822, 0.4465]),\n",
    "#                                std=np.array([0.2023, 0.1994, 0.2010]),\n",
    "                                brightness=0.3, contrast=0.3, saturation=0.3, hue=0.3,\n",
    "                                pca_noise=0.01, rand_gray=0, inter_method=2)\n",
    "    auglist.append(image.RandomOrderAug(_aug))\n",
    "\n",
    "    for aug in auglist:\n",
    "        im = aug(im)\n",
    "        \n",
    "    if random.random() > random_clip_rate:\n",
    "        im = im.clip(0, 1)\n",
    "    _aug = image.ColorNormalizeAug(mean=np.array([0.4914, 0.4822, 0.4465]),\n",
    "                   std=np.array([0.2023, 0.1994, 0.2010]),)\n",
    "    im = _aug(im)\n",
    "    \n",
    "    im = nd.transpose(im, (2, 0, 1))\n",
    "    return (im, nd.array([label]).asscalar().astype('float32'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. data augment: back grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 define a simple back grad method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-13T12:35:56.463007Z",
     "start_time": "2018-03-13T12:35:53.307583Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from cifar10_utils import show_images\n",
    "%matplotlib inline\n",
    "\n",
    "def SGD(data, lr):\n",
    "    data[:] = data - data.grad * lr\n",
    "    \n",
    "def inv_normalize(data, clip=True):\n",
    "    mean=np.array([0.4914, 0.4822, 0.4465])\n",
    "    std=np.array([0.2023, 0.1994, 0.2010])\n",
    "    images = data.transpose((0, 2, 3, 1)).asnumpy()\n",
    "    images = images * std + mean\n",
    "    images = images.transpose((0, 3, 1, 2)) * 255\n",
    "    if clip: \n",
    "        images = images.clip(0, 255)\n",
    "    return images\n",
    "    \n",
    "def show_data(data, clip=True):\n",
    "    images = inv_normalize(data, clip)\n",
    "    show_images(images)\n",
    "    \n",
    "def generate_backgrad_data(net, data, label, max_iters=60, lr=0.1, iter_log=False, clip=True, combine_batch=False):\n",
    "    for iters in range(1, max_iters+1):\n",
    "        with autograd.record():\n",
    "            data.attach_grad()\n",
    "            output = net(data.as_in_context(ctx))\n",
    "            loss = -loss_f(output, label.as_in_context(ctx))\n",
    "        loss.backward()\n",
    "        \n",
    "        if iter_log and iters % 50 == 0:\n",
    "            show_data(data[:10], clip)\n",
    "            print data[0, 0, :2, :10]\n",
    "            print data.grad[0, 0, :2, :10]\n",
    "        if iter_log and iters % 5 == 0:\n",
    "            print 'iter:', iters, 'loss:', nd.mean(loss).asscalar()\n",
    "        \n",
    "        SGD(data, lr)\n",
    "    return data, (nd.mean(loss).asscalar(),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-13T12:35:56.480536Z",
     "start_time": "2018-03-13T12:35:56.466591Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_soft_label(y, num_class, soft_label_th):\n",
    "    y = y.reshape((-1,))\n",
    "    ny = (y.one_hot(num_class) + soft_label_th / num_class)\n",
    "    y = y.asnumpy()\n",
    "    ny[range(y.shape[0]), y.astype('int32')] -= soft_label_th\n",
    "    return nd.array(ny)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. define train function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-10T07:52:58.780872Z",
     "start_time": "2018-03-10T07:52:54.815053Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data, valid_data = data_loader(32, transform_train_DA1, num_workers=4, \n",
    "                                     pathes=[arrayds_dir + 'backgrad_resnet18_me_200e_iter10.ndarray']\n",
    "                                     , arrayds=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-10T07:18:36.901174Z",
     "start_time": "2018-03-10T07:18:26.895949Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "backgrad image acc for origin net:  0.444177863084\n"
     ]
    }
   ],
   "source": [
    "net = ResNet(10)\n",
    "net.initialize(ctx=ctx)\n",
    "net.hybridize()\n",
    "net.load_params(\"../../models/resnet18_me_200e\", ctx=ctx)\n",
    "\n",
    "print \"backgrad image acc for origin net: \", utils.evaluate_accuracy(train_data, net, ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-10T07:18:46.881552Z",
     "start_time": "2018-03-10T07:18:36.902730Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "backgrad image acc for net trained with backgrad_iter10:  1.0\n"
     ]
    }
   ],
   "source": [
    "net = ResNet(10)\n",
    "net.initialize(ctx=ctx)\n",
    "net.hybridize()\n",
    "net.load_params(\"../../models/resnet18_me_200e_backgrad_iter10\", ctx=ctx)\n",
    "\n",
    "print \"backgrad image acc for net trained with backgrad_iter10: \", utils.evaluate_accuracy(train_data, net, ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-10T07:18:57.318606Z",
     "start_time": "2018-03-10T07:18:46.882890Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "backgrad image acc for net trained with backgrad_iter15:  0.999580134357\n"
     ]
    }
   ],
   "source": [
    "net = ResNet(10)\n",
    "net.initialize(ctx=ctx)\n",
    "net.hybridize()\n",
    "net.load_params(\"../../models/resnet18_me_200e_backgrad\", ctx=ctx) # iter15\n",
    "\n",
    "print \"backgrad image acc for net trained with backgrad_iter15: \", utils.evaluate_accuracy(train_data, net, ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-10T07:53:18.220303Z",
     "start_time": "2018-03-10T07:53:06.855223Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "backgrad image acc for net trained online:  0.981825815739\n"
     ]
    }
   ],
   "source": [
    "net = ResNet(10)\n",
    "net.initialize(ctx=ctx)\n",
    "net.hybridize()\n",
    "net.load_params(\"../../models/resnet18_me_backgrad_prob_online_iter10_lr01_softlabel01_addbatch\", ctx=ctx)\n",
    "print \"backgrad image acc for net trained online: \", utils.evaluate_accuracy(train_data, net, ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-10T07:58:16.860720Z",
     "start_time": "2018-03-10T07:58:07.026537Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "backgrad image loss for net trained online:  0.123514819562\n"
     ]
    }
   ],
   "source": [
    "loss_f = gluon.loss.SoftmaxCrossEntropyLoss()\n",
    "loss, num = 0., 0\n",
    "for data, label in train_data:\n",
    "    output = net(data.as_in_context(ctx))\n",
    "    loss += nd.sum(loss_f(output, label.as_in_context(ctx))).asscalar()\n",
    "    num += data.shape[0]\n",
    "print \"backgrad image loss for net trained online: \", loss / num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-13T12:54:26.775406Z",
     "start_time": "2018-03-13T12:54:26.591262Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train_ds = MyArrayDataset(load_all_data_label([arrayds_dir + 'origin.ndarray']), transform=transform_train_DA1)\n",
    "# train_data = gluon.data.DataLoader(train_ds, 32, shuffle=False, num_workers=0)\n",
    "train_ds = MyArrayDataset(load_all_data_label([arrayds_dir + 'origin.ndarray']), transform=_transform_test)\n",
    "train_data = gluon.data.DataLoader(train_ds, 32, shuffle=False, num_workers=0)\n",
    "net = ResNet(10)\n",
    "net.initialize(ctx=ctx)\n",
    "net.hybridize()\n",
    "net.load_params(\"../../models/resnet18_me_backgrad_prob_online_iter10_lr01\", ctx=ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-13T12:59:13.467614Z",
     "start_time": "2018-03-13T12:54:31.613552Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "999\n",
      "0.1969 -0.315220886602\n"
     ]
    }
   ],
   "source": [
    "loss_f = gluon.loss.SoftmaxCrossEntropyLoss()\n",
    "num, right, loss = 0., 0., 0.\n",
    "for i, (data, label) in enumerate(train_data):\n",
    "    loss_f = gluon.loss.SoftmaxCrossEntropyLoss()\n",
    "    grad_data, (_loss, ) = generate_backgrad_data(net, data.copy(), label, max_iters=10, lr=0.1, clip=False)\n",
    "    output = net(grad_data.as_in_context(ctx))\n",
    "    result = output.argmax(axis=1)\n",
    "    right += nd.sum(result == label.reshape(shape=result.shape).as_in_context(ctx)).asscalar()\n",
    "    num += data.shape[0]\n",
    "    loss += _loss\n",
    "    \n",
    "    if (i + 1) % 500 == 0:\n",
    "        print i\n",
    "    \n",
    "print right / num , loss / num\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-13T12:11:33.982080Z",
     "start_time": "2018-03-13T12:11:33.049748Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "ssap_exp_config": {
   "error_alert": "Error Occurs!",
   "initial": [],
   "max_iteration": 1000,
   "recv_id": "",
   "running": [],
   "summary": [],
   "version": "1.1.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
