{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. data prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-10T08:51:00.545025Z",
     "start_time": "2018-03-10T08:49:52.706891Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "\n",
    "def mkdir_if_not_exist(path):\n",
    "    if not os.path.exists(os.path.join(*path)):\n",
    "        os.makedirs(os.path.join(*path))\n",
    "\n",
    "market_dir = '/home/hui/dataset/market1501/'\n",
    "save_dir = market_dir + \"/features\"\n",
    "force_regenerate = False\n",
    "if force_regenerate or (not os.path.exists(market_dir + 'classify/')):\n",
    "    classfy_dir = os.path.join(market_dir, 'classify/')\n",
    "    mkdir_if_not_exist([classfy_dir])\n",
    "    images_dir = market_dir + 'bounding_box_train'\n",
    "    for i, image_name in enumerate(os.listdir(images_dir)):\n",
    "        if image_name.split('.')[-1] != 'jpg': continue\n",
    "        person_id = image_name.split('_')[0]\n",
    "        mkdir_if_not_exist([classfy_dir, person_id])\n",
    "        shutil.copy(os.path.join(images_dir, image_name), os.path.join(classfy_dir, person_id))\n",
    "        if i % 1000==0: print i, image_name, person_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. import needed package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-10T08:54:57.535071Z",
     "start_time": "2018-03-10T08:54:57.527380Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/Util/miniconda/lib/python2.7/site-packages/ipykernel/pylab/config.py:66: DeprecationWarning: metadata {'config': True} was set from the constructor.  Metadata should be set using the .tag() method, e.g., Int().tag(key1='value1', key2='value2')\n",
      "  inline backend.\"\"\"\n",
      "/root/Util/miniconda/lib/python2.7/site-packages/ipykernel/pylab/config.py:71: DeprecationWarning: metadata {'config': True} was set from the constructor.  Metadata should be set using the .tag() method, e.g., Int().tag(key1='value1', key2='value2')\n",
      "  'retina', 'jpeg', 'svg', 'pdf'.\"\"\")\n",
      "/root/Util/miniconda/lib/python2.7/site-packages/ipykernel/pylab/config.py:85: DeprecationWarning: metadata {'config': True} was set from the constructor.  Metadata should be set using the .tag() method, e.g., Int().tag(key1='value1', key2='value2')\n",
      "  use `figure_formats` instead)\"\"\")\n",
      "/root/Util/miniconda/lib/python2.7/site-packages/ipykernel/pylab/config.py:95: DeprecationWarning: metadata {'config': True} was set from the constructor.  Metadata should be set using the .tag() method, e.g., Int().tag(key1='value1', key2='value2')\n",
      "  \"\"\"\n",
      "/root/Util/miniconda/lib/python2.7/site-packages/ipykernel/pylab/config.py:114: DeprecationWarning: metadata {'config': True} was set from the constructor.  Metadata should be set using the .tag() method, e.g., Int().tag(key1='value1', key2='value2')\n",
      "  \"\"\")\n",
      "/root/Util/miniconda/lib/python2.7/site-packages/ipykernel/pylab/config.py:44: DeprecationWarning: InlineBackend._config_changed is deprecated: use @observe and @unobserve instead.\n",
      "  def _config_changed(self, name, old, new):\n",
      "/root/Util/miniconda/lib/python2.7/site-packages/traitlets/traitlets.py:770: DeprecationWarning: A parent of InlineBackend._config_changed has adopted the new @observe(change) API\n",
      "  clsname, change_or_name), DeprecationWarning)\n",
      "/root/Util/miniconda/lib/python2.7/site-packages/IPython/core/formatters.py:98: DeprecationWarning: DisplayFormatter._formatters_default is deprecated: use @default decorator instead.\n",
      "  def _formatters_default(self):\n",
      "/root/Util/miniconda/lib/python2.7/site-packages/IPython/core/formatters.py:677: DeprecationWarning: PlainTextFormatter._deferred_printers_default is deprecated: use @default decorator instead.\n",
      "  def _deferred_printers_default(self):\n",
      "/root/Util/miniconda/lib/python2.7/site-packages/IPython/core/formatters.py:669: DeprecationWarning: PlainTextFormatter._singleton_printers_default is deprecated: use @default decorator instead.\n",
      "  def _singleton_printers_default(self):\n",
      "/root/Util/miniconda/lib/python2.7/site-packages/IPython/core/formatters.py:672: DeprecationWarning: PlainTextFormatter._type_printers_default is deprecated: use @default decorator instead.\n",
      "  def _type_printers_default(self):\n",
      "/root/Util/miniconda/lib/python2.7/site-packages/IPython/core/formatters.py:672: DeprecationWarning: PlainTextFormatter._type_printers_default is deprecated: use @default decorator instead.\n",
      "  def _type_printers_default(self):\n",
      "/root/Util/miniconda/lib/python2.7/site-packages/IPython/core/formatters.py:677: DeprecationWarning: PlainTextFormatter._deferred_printers_default is deprecated: use @default decorator instead.\n",
      "  def _deferred_printers_default(self):\n"
     ]
    }
   ],
   "source": [
    "from mxnet import autograd\n",
    "from mxnet import gluon\n",
    "from mxnet import image\n",
    "from mxnet import init\n",
    "from mxnet import nd\n",
    "from mxnet.gluon.model_zoo import vision as model\n",
    "from mxnet.gluon import nn\n",
    "from mxnet.gluon.data import vision\n",
    "import numpy as np\n",
    "import random\n",
    "import mxnet as mx\n",
    "import sys\n",
    "sys.path.insert(0, '../../utils')\n",
    "from dataset import *\n",
    "from netlib import *\n",
    "import os\n",
    "import shutil\n",
    "from cifar10_utils import show_images\n",
    "%matplotlib inline\n",
    "import mxnet.gluon.model_zoo.vision as models\n",
    "from tqdm import tqdm\n",
    "\n",
    "ctx = mx.gpu(0)\n",
    "num_classes = 751\n",
    "def mkdir_if_not_exist(path):\n",
    "    if not os.path.exists(os.path.join(*path)):\n",
    "        os.makedirs(os.path.join(*path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. data loader, data argument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-10T08:21:55.780527Z",
     "start_time": "2018-03-10T08:21:55.756096Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "data loader\n",
    "\"\"\"\n",
    "batch_size = 16\n",
    "# imagenet mean and std, set None or not set will use as default for image.CreateAugmenter function\n",
    "mean = np.array([123.68, 116.28, 103.53])\n",
    "std = np.array([58.395, 57.12, 57.375])\n",
    "\n",
    "def _transform_test(data, label):\n",
    "    im = data.astype('float32')\n",
    "    im = image.imresize(im, 224, 224, interp=1) / 255\n",
    "    auglist = image.CreateAugmenter(data_shape=(3, 224, 224), rand_crop=False, mean=mean, std=std)\n",
    "    for aug in auglist:\n",
    "        im = aug(im)\n",
    "    im = nd.transpose(im, (2, 0, 1))\n",
    "    return im, nd.array([label]).astype('float32')\n",
    "\n",
    "def inv_normalize(data, clip=True):\n",
    "    images = data.transpose((0, 2, 3, 1)).asnumpy()\n",
    "    images = images * std + mean\n",
    "    images = images.transpose((0, 3, 1, 2)) * 255\n",
    "    if clip: \n",
    "        images = images.clip(0, 255)\n",
    "    return images\n",
    "\n",
    "def load_all_data_label(pathes):\n",
    "    all_data, all_label = None, None\n",
    "    for path in pathes:\n",
    "        data, label = nd.load(path)\n",
    "        label = label.reshape((-1,)).astype('float32')\n",
    "        if all_data is None:\n",
    "            all_data, all_label = data, label\n",
    "        else:\n",
    "            all_data = nd.concat(all_data, data, dim=0)\n",
    "            all_label = nd.concat(all_label, label, dim=0)\n",
    "    return all_data, all_label\n",
    "\n",
    "\n",
    "def data_loader(batch_size, transform_train, transform_test=None, num_workers=0, pathes=None, arrayds=False):\n",
    "    if transform_train is None:\n",
    "        transform_train = _transform_train\n",
    "    if transform_test is None:\n",
    "        transform_test = _transform_test\n",
    "        \n",
    "    # flag=1 mean 3 channel image\n",
    "    if pathes is None:\n",
    "        train_ds = gluon.data.vision.datasets.ImageFolderDataset(root=market_dir + '/classify/', flag=1, transform=transform_train)\n",
    "    else:\n",
    "        if not arrayds:\n",
    "            train_ds = MultiFolderDataset(pathes, transform=transform_train)\n",
    "        else:\n",
    "            train_ds = MyArrayDataset(load_all_data_label(pathes), transform=transform_train)\n",
    "    #test_ds = gluon.data.vision.datasets.CIFAR10(root='~/.mxnet/datasets/cifar10', train=False, transform=transform_test)\n",
    "\n",
    "    loader = gluon.data.DataLoader\n",
    "    train_data = loader(train_ds, batch_size, shuffle=True, last_batch='keep', num_workers=num_workers)\n",
    "    #test_data = loader(test_ds, batch_size, shuffle=False, last_batch='keep', num_workers=num_workers)\n",
    "    return train_data, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-10T08:21:55.863120Z",
     "start_time": "2018-03-10T08:21:55.781902Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "data argument\n",
    "\"\"\"\n",
    "def transform_train_DA1(data, label):\n",
    "    im = data.astype('float32')\n",
    "    im = image.imresize(im, 224, 224, interp=1) / 255\n",
    "    auglist = image.CreateAugmenter(data_shape=(3, 224, 224), rand_crop=False, rand_mirror=True, mean=mean, std=std)\n",
    "    for aug in auglist:\n",
    "        im = aug(im)\n",
    "    im = nd.transpose(im, (2, 0, 1)) # channel x width x height\n",
    "    return im, nd.array([label]).astype('float32')\n",
    "\n",
    "\"\"\"\n",
    "def transform_train_DA2(data, label):\n",
    "    im = data.astype(np.float32) / 255\n",
    "    auglist = [image.RandomSizedCropAug(size=(32, 32), min_area=0.49, ratio=(0.5, 2))]\n",
    "    _aug = image.CreateAugmenter(data_shape=(3, 32, 32), resize=0, \n",
    "                                rand_crop=False, rand_resize=False, rand_mirror=True,\n",
    "                                mean=np.array([0.4914, 0.4822, 0.4465]),\n",
    "                                std=np.array([0.2023, 0.1994, 0.2010]),\n",
    "                                brightness=0.3, contrast=0.3, saturation=0.3, hue=0.3,\n",
    "                                pca_noise=0.01, rand_gray=0, inter_method=2)\n",
    "    auglist.append(image.RandomOrderAug(_aug))\n",
    "    \n",
    "    for aug in auglist:\n",
    "        im = aug(im)\n",
    "    \n",
    "    im = nd.transpose(im, (2, 0, 1))\n",
    "    return (im, nd.array([label]).asscalar().astype('float32'))\n",
    "    \n",
    "\n",
    "random_clip_rate = 0.3\n",
    "def transform_train_DA3(data, label):\n",
    "    im = data.astype(np.float32) / 255\n",
    "    auglist = [image.RandomSizedCropAug(size=(32, 32), min_area=0.49, ratio=(0.5, 2))]\n",
    "    _aug = image.CreateAugmenter(data_shape=(3, 32, 32), resize=0, \n",
    "                                rand_crop=False, rand_resize=False, rand_mirror=True,\n",
    "#                                mean=np.array([0.4914, 0.4822, 0.4465]),\n",
    "#                                std=np.array([0.2023, 0.1994, 0.2010]),\n",
    "                                brightness=0.3, contrast=0.3, saturation=0.3, hue=0.3,\n",
    "                                pca_noise=0.01, rand_gray=0, inter_method=2)\n",
    "    auglist.append(image.RandomOrderAug(_aug))\n",
    "\n",
    "    for aug in auglist:\n",
    "        im = aug(im)\n",
    "        \n",
    "    if random.random() > random_clip_rate:\n",
    "        im = im.clip(0, 1)\n",
    "    _aug = image.ColorNormalizeAug(mean=np.array([0.4914, 0.4822, 0.4465]),\n",
    "                   std=np.array([0.2023, 0.1994, 0.2010]),)\n",
    "    im = _aug(im)\n",
    "    \n",
    "    im = nd.transpose(im, (2, 0, 1))\n",
    "    return (im, nd.array([label]).asscalar().astype('float32'))\n",
    "\"\"\"\n",
    "print "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. define train function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-10T08:22:05.777964Z",
     "start_time": "2018-03-10T08:22:05.592019Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "train\n",
    "\"\"\"\n",
    "import datetime\n",
    "import utils\n",
    "import sys\n",
    "from random import random\n",
    "\n",
    "num_class = 10\n",
    "\n",
    "def abs_mean(W):\n",
    "    return nd.mean(nd.abs(W)).asscalar()\n",
    "\n",
    "def in_list(e, l):\n",
    "    for i in l:\n",
    "        if i == e:\n",
    "            return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def train(net, train_data, valid_data, num_epochs, lr, lr_period, \n",
    "          lr_decay, wd, ctx, w_key, output_file=None, verbose=False, loss_f=gluon.loss.SoftmaxCrossEntropyLoss(), \n",
    "          use_mixup=False, mixup_alpha=0.2, back_grad_args=None):\n",
    "    \n",
    "    def train_batch(data, label, i, use_backgrad, loss_f):\n",
    "        data = data.as_in_context(ctx)\n",
    "        _label = label.copy()\n",
    "        label = label.as_in_context(ctx)\n",
    "        \n",
    "        # generate backgrad data\n",
    "        _bloss = None\n",
    "        if use_backgrad:\n",
    "            args = back_grad_args\n",
    "            args['prob'] = args.get('prob', 1)      # prob to use back grad data argument to prove origin data is used.\n",
    "            if random() <= args['prob']:\n",
    "                args['max_iters'], args['lr'] = args.get('max_iters', 60), args.get('lr', 0.1)\n",
    "                _data, (_bloss,) = generate_backgrad_data(args['net'], data, label, args['max_iters'], args['lr'], iter_log=False)\n",
    "                if args.has_key('soft_label_th'):\n",
    "                    label = get_soft_label(label, num_class, args['soft_label_th'])\n",
    "                    loss_f = args['soft_label_loss_f']\n",
    "                    \n",
    "                if args.has_key('show_iters') and i % args['show_iters'] == 0:\n",
    "                    show_data(data[:5])\n",
    "                    \n",
    "                if args.has_key('attach_batch') and args['attach_batch'] == True:\n",
    "                    data = nd.concat(data, _data, dim=0)\n",
    "                    label = nd.concat(label, label, dim=0)\n",
    "                    _label = nd.concat(_label, _label, dim=0)\n",
    "                else:\n",
    "                    data = _data\n",
    "                    \n",
    "        label = label.as_in_context(ctx)            \n",
    "        with autograd.record():\n",
    "            output = net(data.as_in_context(ctx))\n",
    "            loss = loss_f(output, label)\n",
    "        loss.backward()\n",
    "        trainer.step(data.shape[0])\n",
    "\n",
    "        _loss = nd.mean(loss).asscalar()\n",
    "#         if not use_mixup and (back_grad_args is None or not args.has_key('soft_label_th')):\n",
    "#             _acc = utils.accuracy(output, label)\n",
    "        if not use_mixup:\n",
    "            _acc = utils.accuracy(output, _label.as_in_context(ctx))\n",
    "        else:\n",
    "            _acc = None\n",
    "\n",
    "        if verbose and i % 100 == 0:\n",
    "            print \" # iter\", i,\n",
    "            print \"loss %.5f\" % _loss, \n",
    "            if not use_mixup: print \"acc %.5f\" % _acc,\n",
    "            print \"w (\",\n",
    "            for k in w_key:\n",
    "                w = net.collect_params()[k]\n",
    "                print \"%.5f, \" % abs_mean(w.data()),\n",
    "            print \") g (\",\n",
    "            for k in w_key:\n",
    "                w = net.collect_params()[k]\n",
    "                print \"%.5f, \" % abs_mean(w.grad()),\n",
    "            print \")\"\n",
    "        return _loss, _acc, _bloss\n",
    "            \n",
    "    if output_file is None:\n",
    "        output_file = sys.stdout\n",
    "        stdout = sys.stdout\n",
    "    else:\n",
    "        output_file = open(output_file, \"w\")\n",
    "        stdout = sys.stdout\n",
    "        sys.stdout = output_file\n",
    "    trainer = gluon.Trainer(net.collect_params(), 'sgd', {'learning_rate': lr, 'momentum': 0.9, 'wd': wd})\n",
    "    prev_time = datetime.datetime.now()\n",
    "    \n",
    "    if verbose:\n",
    "        print \" #\", utils.evaluate_accuracy(valid_data, net, ctx)\n",
    "    \n",
    "    i = 0\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss = 0.\n",
    "        train_acc = 0.\n",
    "        bloss, btime = 0., 0\n",
    "        if in_list(epoch, lr_period):\n",
    "            trainer.set_learning_rate(trainer.learning_rate * lr_decay)\n",
    "        \n",
    "        # back grad\n",
    "        use_backgrad = False\n",
    "        if back_grad_args is not None:\n",
    "            args = back_grad_args\n",
    "            if args.has_key('take_turn'):\n",
    "                args['take_turn'] = not args['take_turn'] # only odd epoch(start 0) will use back grad\n",
    "\n",
    "            if (not args.has_key('take_turn')) or args['take_turn'] == True:\n",
    "                if not args.has_key('prob'): print \"# back grad turn.\" \n",
    "                use_backgrad = True\n",
    "        \n",
    "        # mixup\n",
    "        if not use_mixup:\n",
    "            for data, label in train_data:\n",
    "                _loss, _acc, _bloss = train_batch(data, label, i, use_backgrad, loss_f)\n",
    "                train_loss += _loss\n",
    "                if _acc is not None: train_acc += _acc\n",
    "                if _bloss is not None: \n",
    "                    bloss += _bloss\n",
    "                    btime += 1\n",
    "                i += 1\n",
    "        else:\n",
    "            for x, y in train_data:\n",
    "                l = x.shape[0] / 2\n",
    "                data, label = mixup(x[:l], y[:l], x[l:2*l], y[l:2*l], mixup_alpha, 10)\n",
    "                _loss, _, _bloss = train_batch(data, label, i, use_backgrad, loss_f)\n",
    "                train_loss += _loss\n",
    "                if _bloss is not None: \n",
    "                    bloss += _bloss\n",
    "                    btime += 1\n",
    "                i += 1\n",
    "        \n",
    "        # log info\n",
    "        cur_time = datetime.datetime.now()\n",
    "        h, remainder = divmod((cur_time - prev_time).seconds, 3600)\n",
    "        m, s = divmod(remainder, 60)\n",
    "        time_str = \"Time %02d:%02d:%02d\" % (h, m, s)\n",
    "        \n",
    "        train_loss /= len(train_data)\n",
    "        train_acc /= len(train_data)\n",
    "        if train_acc < 1e-6:\n",
    "            train_acc = utils.evaluate_accuracy(train_data, net, ctx)\n",
    "        \n",
    "        if valid_data is not None:\n",
    "            valid_acc = utils.evaluate_accuracy(valid_data, net, ctx)\n",
    "            epoch_str = (\"epoch %d, loss %.5f, train_acc %.4f, valid_acc %.4f\" \n",
    "                         % (epoch, train_loss, train_acc, valid_acc))\n",
    "        else:\n",
    "            epoch_str = (\"epoch %d, loss %.5f, train_acc %.4f\"\n",
    "                        % (epoch, train_loss, train_acc))\n",
    "            \n",
    "        if back_grad_args is not None:\n",
    "            epoch_str += (\", bloss %.5f\" % (-bloss / btime))\n",
    "        prev_time = cur_time\n",
    "        output_file.write(epoch_str + \", \" + time_str + \",lr \" + str(trainer.learning_rate) + \"\\n\")\n",
    "        output_file.flush()  # to disk only when flush or close\n",
    "    if output_file != stdout:\n",
    "        sys.stdout = stdout\n",
    "        output_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. get net and do EXP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_image_info(image_dir, image_name, transform=None):\n",
    "    img = image.imread(os.path.join(image_dir, image_name), flag=1)\n",
    "    image_name_list = image_name.split('_')\n",
    "    label = int(image_name_list[0])\n",
    "    cam = int(image_name_list[1].split('s')[0][1:])\n",
    "    if transform is not None: \n",
    "        img, label = transform(img, label)\n",
    "    return img, label, cam\n",
    "\n",
    "def test_data_loader(image_dir, batch_size):\n",
    "    batch_data, batch_label, batch_cam, batch_i = None, nd.zeros(shape=(batch_size,)), nd.zeros(shape=(batch_size,)), 0\n",
    "    for image_name in os.listdir(image_dir):\n",
    "        if image_name.split('.')[-1] != 'jpg': continue\n",
    "        if int(image_name.split('_')[0]) == -1: continue\n",
    "        image_path = os.path.join(image_dir, image_name)\n",
    "        img, label, cam = get_image_info(image_dir, image_name, transform=_transform_test)\n",
    "        if batch_data is None:\n",
    "            batch_data = nd.zeros(shape=(batch_size, img.shape[0], img.shape[1], img.shape[2]))\n",
    "        batch_data[batch_i, :, :, :] = img[:, :, :]\n",
    "        batch_label[batch_i] = label\n",
    "        batch_cam[batch_i] = cam\n",
    "        batch_i += 1\n",
    "        if batch_i == batch_size:\n",
    "            yield batch_data, batch_label, batch_cam\n",
    "            batch_i = 0\n",
    "    if batch_i > 0:\n",
    "        yield batch_data[:batch_i, :, :, :], batch_label[:batch_i], batch_cam[:batch_i]\n",
    "\n",
    "def save_features_of_dir(net, image_dir, save_prefix):\n",
    "    features, labels, cams = None, None, None\n",
    "    for i, (data, label, cam) in tqdm(enumerate(test_data_loader(image_dir, batch_size=16))):\n",
    "        feature = net(data.as_in_context(ctx))\n",
    "        feature = feature.reshape((feature.shape[0], -1))\n",
    "        if features is None:\n",
    "            features, labels, cams = feature.copy(), label.copy(), cam.copy()\n",
    "        else:\n",
    "            features = nd.concat(features, feature, dim=0)\n",
    "            labels = nd.concat(labels, label, dim=0)\n",
    "            cams = nd.concat(cams, cam, dim=0)\n",
    "    print \"process all %d images over\" % features.shape[0]\n",
    "    np.save(save_prefix + 'features', features.asnumpy())\n",
    "    np.save(save_prefix + 'labels', labels.asnumpy())\n",
    "    np.save(save_prefix + 'cams', cams.asnumpy())\n",
    "    print \"all done.\"\n",
    "    \n",
    "\n",
    "from reid_evaluate import evaluate\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "def cal_CMC(prefix):\n",
    "    query_feature = normalize(np.load(prefix + 'q_features.npy'), 'l2', axis=1)\n",
    "    query_cam = np.load(prefix + 'q_cams.npy')\n",
    "    query_label = np.load(prefix + 'q_labels.npy')\n",
    "    gallery_feature = normalize(np.load(prefix + 'g_features.npy'), 'l2', axis=1)\n",
    "    gallery_cam = np.load(prefix + 'g_cams.npy')\n",
    "    gallery_label = np.load(prefix + 'g_labels.npy')\n",
    "\n",
    "    CMC = np.zeros(shape=(len(gallery_label),)) # torch.IntTensor(len(gallery_label)).zero_()\n",
    "    ap = 0.0\n",
    "    #print(query_label)\n",
    "    for i in tqdm(range(len(query_label))):\n",
    "        ap_tmp, CMC_tmp = evaluate(query_feature[i],query_label[i],query_cam[i],gallery_feature,gallery_label,gallery_cam)\n",
    "        if CMC_tmp[0]==-1:\n",
    "            continue\n",
    "        CMC = CMC + CMC_tmp\n",
    "        ap += ap_tmp\n",
    "        #print(i, CMC_tmp[0])\n",
    "\n",
    "    CMC = CMC/len(query_label) #average CMC\n",
    "    print('top1:%f top5:%f top10:%f mAP:%f'%(CMC[0],CMC[4],CMC[9],ap/len(query_label)))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 baseline: general lr policy train my resnet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_resnet50_v1(num_classes, pretrained=True):\n",
    "    net = nn.HybridSequential()\n",
    "    with net.name_scope():\n",
    "        resnet = models.resnet152_v1(pretrained=pretrained, ctx=ctx)\n",
    "        classify = nn.HybridSequential()\n",
    "        with classify.name_scope():\n",
    "            classify.add(nn.Dense(1024)) # fc6\n",
    "            classify.add(nn.BatchNorm())\n",
    "            classify.add(nn.Dropout(0.5))\n",
    "            classify.add(nn.Activation(activation='relu'))\n",
    "            classify.add(nn.Dense(num_classes)) # fc7\n",
    "        net.add(resnet.features)\n",
    "        net.add(classify)\n",
    "\n",
    "    net.hybridize()\n",
    "    if pretrained:\n",
    "        classify.initialize(ctx=ctx)\n",
    "    else:\n",
    "        net.initialize(ctx=ctx)\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, loss 6.34605, train_acc 0.0284, Time 00:13:17,lr 0.001\n",
      "epoch 1, loss 4.97933, train_acc 0.1042, Time 00:13:12,lr 0.001\n",
      "epoch 2, loss 3.99680, train_acc 0.2145, Time 00:13:16,lr 0.001\n",
      "epoch 3, loss 3.16246, train_acc 0.3435, Time 00:13:15,lr 0.001\n",
      "epoch 4, loss 2.42953, train_acc 0.4753, Time 00:13:10,lr 0.001\n",
      "epoch 5, loss 1.82129, train_acc 0.6095, Time 00:13:13,lr 0.001\n",
      "epoch 6, loss 1.33489, train_acc 0.7177, Time 00:13:06,lr 0.001\n",
      "epoch 7, loss 0.97611, train_acc 0.8042, Time 00:13:11,lr 0.001\n",
      "epoch 8, loss 0.69738, train_acc 0.8702, Time 00:13:11,lr 0.001\n",
      "epoch 9, loss 0.50405, train_acc 0.9122, Time 00:13:10,lr 0.001\n",
      "epoch 10, loss 0.35792, train_acc 0.9434, Time 00:13:10,lr 0.001\n",
      "epoch 11, loss 0.25563, train_acc 0.9658, Time 00:13:10,lr 0.001\n",
      "epoch 12, loss 0.19256, train_acc 0.9784, Time 00:13:11,lr 0.001\n",
      "epoch 13, loss 0.14121, train_acc 0.9862, Time 00:13:10,lr 0.001\n",
      "epoch 14, loss 0.10664, train_acc 0.9913, Time 00:13:08,lr 0.001\n",
      "epoch 15, loss 0.08500, train_acc 0.9945, Time 00:13:13,lr 0.001\n",
      "epoch 16, loss 0.06428, train_acc 0.9968, Time 00:13:19,lr 0.001\n",
      "epoch 17, loss 0.05786, train_acc 0.9975, Time 00:13:12,lr 0.001\n",
      "epoch 18, loss 0.04474, train_acc 0.9981, Time 00:13:05,lr 0.001\n",
      "epoch 19, loss 0.03786, train_acc 0.9994, Time 00:13:08,lr 0.001\n",
      "epoch 20, loss 0.03400, train_acc 0.9995, Time 00:13:17,lr 0.001\n",
      "epoch 21, loss 0.02969, train_acc 0.9997, Time 00:13:12,lr 0.001\n",
      "epoch 22, loss 0.02618, train_acc 0.9998, Time 00:13:13,lr 0.001\n",
      "epoch 23, loss 0.02508, train_acc 0.9997, Time 00:13:19,lr 0.001\n",
      "epoch 24, loss 0.02259, train_acc 1.0000, Time 00:13:14,lr 0.001\n",
      "epoch 25, loss 0.02022, train_acc 0.9999, Time 00:13:13,lr 0.0001\n",
      "epoch 26, loss 0.02006, train_acc 0.9999, Time 00:13:16,lr 0.0001\n",
      "epoch 27, loss 0.01939, train_acc 0.9998, Time 00:13:13,lr 0.0001\n",
      "epoch 28, loss 0.01816, train_acc 0.9998, Time 00:13:14,lr 0.0001\n",
      "epoch 29, loss 0.01899, train_acc 1.0000, Time 00:13:11,lr 0.0001\n",
      "epoch 30, loss 0.01821, train_acc 0.9999, Time 00:13:13,lr 0.0001\n",
      "epoch 31, loss 0.01794, train_acc 0.9995, Time 00:13:10,lr 0.0001\n",
      "epoch 32, loss 0.01829, train_acc 1.0000, Time 00:13:07,lr 0.0001\n",
      "epoch 33, loss 0.01755, train_acc 1.0000, Time 00:13:11,lr 0.0001\n",
      "epoch 34, loss 0.01725, train_acc 1.0000, Time 00:13:11,lr 0.0001\n",
      "epoch 35, loss 0.01753, train_acc 1.0000, Time 00:13:16,lr 0.0001\n",
      "epoch 36, loss 0.01775, train_acc 0.9999, Time 00:13:11,lr 0.0001\n",
      "epoch 37, loss 0.01689, train_acc 1.0000, Time 00:13:13,lr 0.0001\n",
      "epoch 38, loss 0.01729, train_acc 1.0000, Time 00:13:10,lr 0.0001\n",
      "epoch 39, loss 0.01665, train_acc 1.0000, Time 00:13:11,lr 0.0001\n",
      "epoch 40, loss 0.01681, train_acc 0.9999, Time 00:13:15,lr 0.0001\n",
      "epoch 41, loss 0.01632, train_acc 1.0000, Time 00:13:08,lr 0.0001\n",
      "epoch 42, loss 0.01632, train_acc 1.0000, Time 00:13:18,lr 0.0001\n",
      "epoch 43, loss 0.01622, train_acc 1.0000, Time 00:13:13,lr 0.0001\n",
      "epoch 44, loss 0.01638, train_acc 0.9999, Time 00:13:17,lr 0.0001\n",
      "epoch 45, loss 0.01633, train_acc 1.0000, Time 00:13:12,lr 0.0001\n",
      "epoch 46, loss 0.01689, train_acc 0.9999, Time 00:13:09,lr 0.0001\n",
      "epoch 47, loss 0.01549, train_acc 1.0000, Time 00:13:17,lr 0.0001\n",
      "epoch 48, loss 0.01642, train_acc 0.9998, Time 00:13:12,lr 0.0001\n",
      "epoch 49, loss 0.01528, train_acc 1.0000, Time 00:13:08,lr 0.0001\n",
      "epoch 50, loss 0.01542, train_acc 1.0000, Time 00:13:13,lr 1e-05\n",
      "epoch 51, loss 0.01498, train_acc 1.0000, Time 00:13:12,lr 1e-05\n",
      "epoch 52, loss 0.01539, train_acc 1.0000, Time 00:13:16,lr 1e-05\n",
      "epoch 53, loss 0.01561, train_acc 1.0000, Time 00:13:12,lr 1e-05\n",
      "epoch 54, loss 0.01545, train_acc 1.0000, Time 00:13:17,lr 1e-05\n",
      "epoch 55, loss 0.01538, train_acc 0.9999, Time 00:13:13,lr 1e-05\n",
      "epoch 56, loss 0.01554, train_acc 1.0000, Time 00:13:10,lr 1e-05\n",
      "epoch 57, loss 0.01541, train_acc 1.0000, Time 00:13:13,lr 1e-05\n",
      "epoch 58, loss 0.01551, train_acc 0.9999, Time 00:13:08,lr 1e-05\n",
      "epoch 59, loss 0.01541, train_acc 1.0000, Time 00:13:13,lr 1e-05\n",
      "epoch 60, loss 0.01534, train_acc 0.9998, Time 00:13:29,lr 1e-05\n",
      "epoch 61, loss 0.01569, train_acc 1.0000, Time 00:13:13,lr 1e-05\n",
      "epoch 62, loss 0.01511, train_acc 1.0000, Time 00:13:06,lr 1e-05\n",
      "epoch 63, loss 0.01596, train_acc 0.9998, Time 00:13:19,lr 1e-05\n",
      "epoch 64, loss 0.01484, train_acc 1.0000, Time 00:13:35,lr 1e-05\n",
      "epoch 65, loss 0.01550, train_acc 0.9999, Time 00:14:00,lr 1e-05\n",
      "epoch 66, loss 0.01511, train_acc 0.9999, Time 00:13:13,lr 1e-05\n",
      "epoch 67, loss 0.01497, train_acc 1.0000, Time 00:13:26,lr 1e-05\n",
      "epoch 68, loss 0.01552, train_acc 1.0000, Time 00:13:00,lr 1e-05\n",
      "epoch 69, loss 0.01534, train_acc 1.0000, Time 00:13:07,lr 1e-05\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 70\n",
    "learning_rate = 0.001\n",
    "weight_decay = 5e-4\n",
    "lr_period = [25, 50]\n",
    "lr_decay=0.1\n",
    "log_file = None\n",
    "loss_f = gluon.loss.SoftmaxCrossEntropyLoss()\n",
    "\n",
    "train_data, valid_data = data_loader(batch_size, transform_train_DA1, num_workers=0)\n",
    "net = get_resnet50_v1(num_classes=num_classes, pretrained=True)\n",
    "net.hybridize()\n",
    "train(net, train_data, valid_data, num_epochs, learning_rate, lr_period, lr_decay, weight_decay, ctx, \n",
    "      [], log_file, False, loss_f)\n",
    "\n",
    "net.save_params(\"../../models/market_resnet50_v1_70e\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "995it [15:42,  1.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "process all 15913 images over\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "211it [02:37,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "process all 3368 images over\n",
      "all done.\n"
     ]
    }
   ],
   "source": [
    "mkdir_if_not_exist([save_dir])\n",
    "net = get_resnet50_v1(num_classes=num_classes, pretrained=True)\n",
    "net.hybridize()\n",
    "net.load_params(\"../../models/market_resnet50_v1_70e\", ctx=ctx)\n",
    "save_features_of_dir(net[0], os.path.join(market_dir, 'bounding_box_test'), save_dir + \"/resnet50_g_\")\n",
    "save_features_of_dir(net[0], os.path.join(market_dir, 'query'), save_dir + \"/resnet50_q_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3368/3368 [00:47<00:00, 70.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top1:0.715855 top5:0.871140 top10:0.915974 mAP:0.447167\n"
     ]
    }
   ],
   "source": [
    "cal_CMC(save_dir + \"/resnet50_\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 baseline2\n",
    "\n",
    "visit https://github.com/layumi/Person_reID_baseline_pytorch/blob/master/model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from mxnet.gluon import nn\n",
    "class ft_net(nn.HybridBlock):\n",
    "    def __init__(self, class_num, **kargs):\n",
    "        super(ft_net, self).__init__(**kargs)\n",
    "        resnet = model.resnet50_v1(pretrained=True)\n",
    "        resnet.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model file is not found. Downloading.\n",
      "Downloading /root/.mxnet/models/resnet50_v1-c940b1a0.zip from https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/models/resnet50_v1-c940b1a0.zip...\n"
     ]
    }
   ],
   "source": [
    "resnet = model.resnet50_v1(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_resnet50_v1_2(num_classes, pretrained=True):\n",
    "    net = nn.HybridSequential()\n",
    "    with net.name_scope():\n",
    "        resnet = models.resnet152_v1(pretrained=pretrained, ctx=ctx)\n",
    "        classify = nn.HybridSequential()\n",
    "        with classify.name_scope():\n",
    "            classify.add(nn.Dense(num_classes)) # fc7\n",
    "        net.add(resnet.features)\n",
    "        net.add(classify)\n",
    "\n",
    "    net.hybridize()\n",
    "    if pretrained:\n",
    "        classify.initialize(ctx=ctx)\n",
    "    else:\n",
    "        net.initialize(ctx=ctx)\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_epochs = 70\n",
    "learning_rate = 0.001\n",
    "weight_decay = 5e-4\n",
    "lr_period = [25, 50]\n",
    "lr_decay=0.1\n",
    "log_file = None\n",
    "loss_f = gluon.loss.SoftmaxCrossEntropyLoss()\n",
    "\n",
    "train_data, valid_data = data_loader(batch_size, transform_train_DA1, num_workers=0)\n",
    "net = get_resnet50_v1_2(num_classes=num_classes, pretrained=True)\n",
    "net.hybridize()\n",
    "train(net, train_data, valid_data, num_epochs, learning_rate, lr_period, lr_decay, weight_decay, ctx, \n",
    "      [], log_file, False, loss_f)\n",
    "\n",
    "net.save_params(\"../../models/market_resnet50_v1_2_70e\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "ssap_exp_config": {
   "error_alert": "Error Occurs!",
   "initial": [],
   "max_iteration": 1000,
   "recv_id": "",
   "running": [],
   "summary": [],
   "version": "1.1.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
